#!/usr/bin/env bash

# @describe ODCrawler API client for searching open directory files
# @arg command "Command to run (search)" [string]
# @arg query "Search query term" [string]
# @option -u --url-query "Search term to match in URLs" [string]
# @option -f --filename-query "Search term to match in filenames" [string]
# @option -e --extension "Filter by file extension(s) (comma-separated)" [string]
# @option --exclude-ext "Exclude file extension(s) (comma-separated, defaults to html)" [string] @default "html,HTML"
# @option -s --size "Number of results to return" [int] @default "40"
# @option --from "Starting offset for pagination" [int] @default "0"
# @flag   -H --highlight "Enable highlighting in results"
# @flag   -j --json "Output raw JSON response"
# @flag   -q --quiet "Suppress colored output"
# @flag   -v --verbose "Show additional details"
# @meta require-tools curl,jq

eval "$(argc --argc-eval "$0" "$@")"

# Initialize default values for argc variables
argc_quiet=${argc_quiet:-0}
argc_highlight=${argc_highlight:-0}
argc_verbose=${argc_verbose:-0}
argc_from=${argc_from:-0}
argc_size=${argc_size:-40}
argc_exclude_ext=${argc_exclude_ext:-"html,HTML"}
argc_extension=${argc_extension:-""}
argc_json=${argc_json:-0}

# Setup colors
setup_colors() {
  if [ "$argc_quiet" = 1 ] || [ -z "$TERM" ] || [ "$TERM" = "dumb" ]; then
    bold="" reset="" blue="" green="" yellow="" cyan="" magenta="" red="" dim=""
  else
    bold=$(tput bold) reset=$(tput sgr0) blue=$(tput setaf 4) green=$(tput setaf 2)
    yellow=$(tput setaf 3) cyan=$(tput setaf 6) magenta=$(tput setaf 5) red=$(tput setaf 1)
    dim=$(tput dim)
  fi
}
setup_colors

API_BASE="https://search.odcrawler.xyz/elastic/links/_search"

# Helper functions
print_kv() {
  printf "${bold}%s:${reset} %s\n" "$1" "$2"
}

print_section() {
  printf "\n${bold}%s${reset}\n" "$1"
}

format_filesize() {
  local size="$1"
  if [ -z "$size" ] || [ "$size" = "null" ]; then
    echo "N/A"
    return
  fi
  
  if [ "$size" -lt 1024 ]; then
    printf "%d B" "$size"
  elif [ "$size" -lt 1048576 ]; then
    printf "%.1f KB" "$(echo "scale=1; $size / 1024" | bc -l 2>/dev/null || awk "BEGIN {printf \"%.1f\", $size/1024}")"
  elif [ "$size" -lt 1073741824 ]; then
    printf "%.1f MB" "$(echo "scale=1; $size / 1048576" | bc -l 2>/dev/null || awk "BEGIN {printf \"%.1f\", $size/1048576}")"
  else
    printf "%.1f GB" "$(echo "scale=1; $size / 1073741824" | bc -l 2>/dev/null || awk "BEGIN {printf \"%.1f\", $size/1073741824}")"
  fi
}

get_domain() {
  local url="$1"
  echo "$url" | sed -E 's|^https?://([^/]+).*|\1|'
}

clean_html_tags() {
  echo "$1" | sed 's/<[^>]*>//g'
}

build_query() {
  local url_query="$1"
  local filename_query="$2"
  local exclude_extensions="$3"
  local include_extensions="$4"
  
  # Build must array
  local must_clause=""
  if [ -n "$url_query" ]; then
    must_clause="\"must\":[{\"match_phrase\":{\"url\":\"$url_query\"}}],"
  else
    must_clause="\"must\":[{\"match_phrase\":{\"url\":\"\"}}],"
  fi
  
  # Build should array  
  local should_clause=""
  if [ -n "$filename_query" ]; then
    should_clause="\"should\":[{\"match_phrase\":{\"filename\":\"$filename_query\"}}],"
  fi
  
  # Build must_not array for exclusions
  local must_not_clause=""
  if [ -n "$exclude_extensions" ]; then
    local ext_array=""
    IFS=',' read -ra EXTS <<< "$exclude_extensions"
    for ext in "${EXTS[@]}"; do
      ext=$(echo "$ext" | xargs) # trim whitespace
      if [ -n "$ext_array" ]; then
        ext_array="${ext_array},\"$ext\""
      else
        ext_array="\"$ext\""
      fi
    done
    must_not_clause="\"must_not\":[{\"terms\":{\"extension\":[$ext_array]}}]"
  fi
  
  # Build must clause for inclusions
  if [ -n "$include_extensions" ]; then
    local inc_ext_array=""
    IFS=',' read -ra INCS <<< "$include_extensions"
    for ext in "${INCS[@]}"; do
      ext=$(echo "$ext" | xargs) # trim whitespace
      if [ -n "$inc_ext_array" ]; then
        inc_ext_array="${inc_ext_array},\"$ext\""
      else
        inc_ext_array="\"$ext\""
      fi
    done
    if [ -n "$must_not_clause" ]; then
      must_not_clause="${must_not_clause},{\"terms\":{\"extension\":[$inc_ext_array]}}"
    else
      # If we want to include specific extensions, we need to add them to must
      must_clause="${must_clause%,},{\"terms\":{\"extension\":[$inc_ext_array]}},"
    fi
  fi
  
  # Combine clauses
  local bool_query="\"bool\":{"
  [ -n "$must_clause" ] && bool_query="${bool_query}${must_clause}"
  [ -n "$should_clause" ] && bool_query="${bool_query}${should_clause}"
  [ -n "$must_not_clause" ] && bool_query="${bool_query}${must_not_clause}"
  bool_query="${bool_query%,}}"
  
  echo "$bool_query"
}

make_request() {
  local query_json="$1"
  
  local response=$(curl -s \
    -H 'Accept: */*' \
    -H 'Accept-Language: en-US,en;q=0.9' \
    -H 'Cache-Control: no-cache' \
    -H 'Connection: keep-alive' \
    -H 'Content-Type: application/json' \
    -H 'DNT: 1' \
    -H 'Origin: https://odcrawler.xyz' \
    -H 'Pragma: no-cache' \
    -H 'Referer: https://odcrawler.xyz/' \
    -H 'Sec-Fetch-Dest: empty' \
    -H 'Sec-Fetch-Mode: cors' \
    -H 'Sec-Fetch-Site: same-site' \
    -H 'Sec-GPC: 1' \
    -H 'User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari
/537.36' \
    -H 'sec-ch-ua: "Not?A_Brand";v="99", "Chromium";v="130"' \
    -H 'sec-ch-ua-mobile: ?0' \
    -H 'sec-ch-ua-platform: "Linux"' \
    --data-raw "$query_json" \
    "$API_BASE")

  if [ -z "$response" ]; then
    printf "${red}Error:${reset} Empty response from API\n" >&2
    exit 1
  fi

  if echo "$response" | jq -e '.error' >/dev/null 2>&1; then
    error_msg=$(echo "$response" | jq -r '.error.reason // .error')
    printf "${red}Error:${reset} API returned: ${red}%s${reset}\n" "$error_msg" >&2
    exit 1
  fi

  echo "$response"
}

show_help() {
  echo "${bold}ODCrawler API Client${reset}"
  echo ""
  echo "${bold}Description:${reset}"
  echo "  Search for files in open directories using ODCrawler's Elasticsearch API"
  echo ""
  echo "${bold}Commands:${reset}"
  echo "  ${cyan}search${reset}        Search for files by query term"
  echo ""
  echo "${bold}Examples:${reset}"
  echo "  ${green}$(basename "$0") search dotcom${reset}"
  echo "  ${green}$(basename "$0") search --url-query nutrien --filename-query nutrien${reset}"
  echo "  ${green}$(basename "$0") search secret --extension pdf,doc,txt${reset}"
  echo "  ${green}$(basename "$0") search --filename-query config --exclude-ext html,htm,css${reset}"
  echo "  ${green}$(basename "$0") search passwords --size 20 --from 40${reset}"
  echo ""
  echo "${bold}Options:${reset}"
  echo "  ${yellow}-u, --url-query${reset}      Search term to match in URLs"
  echo "  ${yellow}-f, --filename-query${reset} Search term to match in filenames"
  echo "  ${yellow}-e, --extension${reset}      Filter by file extension(s)"
  echo "  ${yellow}--exclude-ext${reset}        Exclude file extension(s) (default: html)"
  echo "  ${yellow}-s, --size${reset}           Number of results (max 40, default: 40)"
  echo "  ${yellow}--from${reset}               Starting offset for pagination"
  echo "  ${yellow}-H, --highlight${reset}      Enable highlighting in results"
  echo "  ${yellow}-j, --json${reset}           Output raw JSON"
  echo "  ${yellow}-q, --quiet${reset}          Suppress colored output"
  echo "  ${yellow}-v, --verbose${reset}        Show additional details"
}

format_search_results() {
  local response="$1"
  
  local total=$(echo "$response" | jq -r '.hits.total.value')
  local took=$(echo "$response" | jq -r '.took')
  local max_score=$(echo "$response" | jq -r '.hits.max_score // "N/A"')
  local results_count=$(echo "$response" | jq -r '.hits.hits | length')
  
  printf "${bold}Search Results${reset}\n\n"
  
  print_kv "Total Results" "${green}${total}${reset}"
  print_kv "Showing" "${yellow}${results_count}${reset} results"
  print_kv "Query Time" "${cyan}${took}ms${reset}"
  [ "$max_score" != "N/A" ] && print_kv "Max Score" "${magenta}${max_score}${reset}"
  
  if [ "$results_count" -eq 0 ]; then
    printf "\n${yellow}No results found${reset}\n"
    return
  fi
  
  print_section "Files Found"
  
  local counter=1
  echo "$response" | jq -c '.hits.hits[]' | while read -r hit; do
    local url=$(echo "$hit" | jq -r '._source.url')
    local filename=$(echo "$hit" | jq -r '._source.filename')
    local extension=$(echo "$hit" | jq -r '._source.extension // "N/A"')
    local score=$(echo "$hit" | jq -r '._score')
    local domain=$(get_domain "$url")
    
    printf "${bold}[%d]${reset} ${green}%s${reset}\n" "$counter" "$filename"
    
    if [ "$argc_highlight" = 1 ]; then
      local highlight_url=$(echo "$hit" | jq -r '.highlight.url[0] // empty')
      local highlight_filename=$(echo "$hit" | jq -r '.highlight.filename[0] // empty')
      
      if [ -n "$highlight_url" ]; then
        printf "     ${dim}URL:${reset} %s\n" "$(clean_html_tags "$highlight_url")"
      fi
      if [ -n "$highlight_filename" ]; then
        printf "     ${dim}File:${reset} %s\n" "$(clean_html_tags "$highlight_filename")"
      fi
    fi
    
    printf "     ${cyan}Link:${reset} ${blue}%s${reset}\n" "$url"
    printf "     ${cyan}Domain:${reset} ${blue}%s${reset}\n" "$domain"
    printf "     ${cyan}Extension:${reset} ${yellow}%s${reset}\n" "$extension"
    printf "     ${cyan}Score:${reset} ${magenta}%.2f${reset}\n" "$score"
    
    printf "\n"
    counter=$((counter + 1))
  done
  
  # Show pagination info
  local from_offset="$argc_from"
  local size_limit="$argc_size"
  local current_page=$(((from_offset / size_limit) + 1))
  local total_pages=$(((total + size_limit - 1) / size_limit))
  
  if [ "$total_pages" -gt 1 ]; then
    printf "${bold}Pagination:${reset} Page ${yellow}%d${reset} of ${yellow}%d${reset}\n" "$current_page" "$total_pages"
    if [ "$current_page" -lt "$total_pages" ]; then
      local next_from=$((from_offset + size_limit))
      printf "${dim}Next page: add ${yellow}--from %d${reset}${dim} to your command${reset}\n" "$next_from"
    fi
  fi
}

# Main command processing
if [ -z "$argc_command" ]; then
  show_help
  exit 0
fi

case "$argc_command" in
search)
  # Determine search strategy
  url_query=""
  filename_query=""
  
  if [ -n "$argc_url_query" ]; then
    url_query="$argc_url_query"
  elif [ -n "$argc_query" ]; then
    url_query="$argc_query"
  fi
  
  if [ -n "$argc_filename_query" ]; then
    filename_query="$argc_filename_query"
  elif [ -n "$argc_query" ] && [ -z "$argc_url_query" ]; then
    filename_query="$argc_query"
  fi
  
  # Build query
  bool_query=$(build_query "$url_query" "$filename_query" "$argc_exclude_ext" "$argc_extension")
  
  # Build highlight section
  highlight_section=""
  if [ "$argc_highlight" = 1 ]; then
    highlight_section='"highlight":{"fields":{"url":{},"filename":{}}},'
  fi
  
  # Build final query JSON
  query_json="{\"size\":$argc_size,\"from\":$argc_from,${highlight_section}\"query\":{$bool_query}}"
  
  if [ "$argc_verbose" = 1 ] && [ "$argc_json" != 1 ]; then
    printf "${dim}Query JSON: %s${reset}\n\n" "$query_json"
  fi
  
  response=$(make_request "$query_json")
  
  if [ "$argc_json" = 1 ]; then
    echo "$response" | jq
  else
    format_search_results "$response"
  fi
  ;;

*)
  printf "${red}Error:${reset} Unknown command: ${argc_command}\n" >&2
  show_help
  exit 1
  ;;
esac

